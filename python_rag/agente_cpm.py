"""
============================================================
 AGENTE CPM - ASSISTENTE PROCESSO SELETIVO 2026.1
============================================================
Autor: Pollyana Sousa
Data: Janeiro/2026
Descri√ß√£o: RAG com Groq para consultas sobre editais CPM
Vers√£o: 3.0 - Limpeza de texto aprimorada
"""
import os
import sys
import pickle
import re
from pathlib import Path
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

# ============================================================
# CARREGAR VARI√ÅVEIS DE AMBIENTE
# ============================================================
env_path = Path(__file__).parent.parent / "backend" / ".env"
load_dotenv(dotenv_path=env_path)

# ============================================================
# 1. CACHE DO VETOR FAISS
# ============================================================
CACHE_FAISS = Path(__file__).parent / "cache_faiss.index"
CACHE_STORE = Path(__file__).parent / "cache_store.pkl"

def salvar_cache(base):
    """Salva FAISS + metadata no disco"""
    base.save_local(str(CACHE_FAISS))
    with open(CACHE_STORE, "wb") as f:
        pickle.dump(base.docstore, f)

def carregar_cache():
    """Carrega FAISS do disco, se existir"""
    if CACHE_FAISS.exists() and CACHE_STORE.exists():
        try:
            embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
            )
            base = FAISS.load_local(
                str(CACHE_FAISS),
                embeddings,
                allow_dangerous_deserialization=True
            )
            with open(CACHE_STORE, "rb") as f:
                base.docstore = pickle.load(f)
            print("‚úì Cache FAISS carregado", file=sys.stderr)
            return base
        except:
            print("Cache inv√°lido, reconstruindo...", file=sys.stderr)
            return None
    return None

# ============================================================
# 2. LIMPEZA PROFUNDA DE TEXTO
# ============================================================
def limpar_texto_pdf(texto):
    """
    Limpa e normaliza texto extra√≠do de PDF
    PROBLEMA IDENTIFICADO: PDFs t√™m espa√ßos m√∫ltiplos entre palavras
    """
    # 1. Normalizar encoding
    try:
        texto = texto.encode("latin-1", "ignore").decode("utf-8", "ignore")
    except:
        pass
    
    # 2. Remover hifeniza√ß√£o de quebra de linha
    texto = re.sub(r"(\w)-\s*\n\s*(\w)", r"\1\2", texto)
    
    # 3. CR√çTICO: Substituir m√∫ltiplos espa√ßos por espa√ßo √∫nico
    # Isso corrige o problema "de   2025" -> "de 2025"
    texto = re.sub(r'\s+', ' ', texto)
    
    # 4. Juntar palavras separadas por quebra de linha
    texto = re.sub(r'(\w)\s*\n\s*(\w)', r'\1 \2', texto)
    
    # 5. Remover quebras de linha excessivas
    texto = re.sub(r'\n\s*\n\s*\n+', '\n\n', texto)
    
    # 6. Remover cabe√ßalhos e rodap√©s comuns
    texto = re.sub(r'P√°gina\s+\d+\s+de\s+\d+', '', texto, flags=re.I)
    texto = re.sub(r'CPM\s+-\s+Conservat√≥rio.*?\n', '', texto, flags=re.I)
    
    # 7. Limpar espa√ßos no in√≠cio e fim
    texto = texto.strip()
    
    return texto

# ============================================================
# 3. CARREGAR PDFs COM LIMPEZA APRIMORADA
# ============================================================
def carregar_pdfs_cpm():
    """Carrega todos os PDFs e cria FAISS se n√£o houver cache."""

    # Tenta usar cache primeiro
    cache = carregar_cache()
    if cache:
        return cache

    pasta_dados = Path(__file__).parent / "dados"
    lista_pdfs = [f.name for f in pasta_dados.glob("*.pdf")]

    documentos = []

    for nome_pdf in lista_pdfs:
        caminho_pdf = pasta_dados / nome_pdf

        if not caminho_pdf.exists():
            print(f"AVISO: PDF n√£o encontrado: {caminho_pdf}", file=sys.stderr)
            continue

        try:
            loader = PyPDFLoader(str(caminho_pdf))
            docs_brutos = loader.load()

            # APLICAR LIMPEZA PROFUNDA
            for d in docs_brutos:
                d.page_content = limpar_texto_pdf(d.page_content)

            # Chunks otimizados
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=600,
                chunk_overlap=150,
                separators=["\n\n", "\n", ". ", " ", ""]
            )

            docs_divididos = text_splitter.split_documents(docs_brutos)
            documentos.extend(docs_divididos)

            print(f"‚úì Carregado: {nome_pdf} ({len(docs_divididos)} trechos)",
                  file=sys.stderr)

        except Exception as e:
            print(f"ERRO ao carregar {nome_pdf}: {str(e)}", file=sys.stderr)

    if not documentos:
        raise Exception("Nenhum documento foi carregado.")

    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
    )

    base = FAISS.from_documents(documentos, embeddings)

    # Salvar cache
    salvar_cache(base)

    return base


# ============================================================
# 4. PROMPT OTIMIZADO
# ============================================================
prompt_principal = ChatPromptTemplate.from_messages([
    ("system", """
Voc√™ √© o Assistente CPM do Conservat√≥rio de M√∫sica de Pernambuco. Voc√™ ajuda candidatos com d√∫vidas sobre o Processo Seletivo 2026.1.

REGRAS FUNDAMENTAIS:
1. Use APENAS informa√ß√µes que est√£o no contexto fornecido
2. Responda de forma DIRETA e OBJETIVA
3. Cite datas, hor√°rios e documentos EXATAMENTE como aparecem
4. NUNCA diga "n√£o encontrei" se a informa√ß√£o estiver no contexto

ENTENDENDO TERMOS DO PROCESSO SELETIVO:
‚Ä¢ INSCRI√á√ÉO = per√≠odo para se inscrever no processo seletivo
‚Ä¢ MATR√çCULA = per√≠odo para efetivar a vaga ap√≥s aprova√ß√£o
‚Ä¢ APROVADOS = lista de quem passou no processo
‚Ä¢ REMANEJAMENTO = preenchimento de vagas n√£o ocupadas

DIFERENCIA√á√ÉO REGULAR vs T√âCNICO:
‚Ä¢ Se pergunta mencionar "regular" ou "t√©cnico" ‚Üí responda sobre esse curso
‚Ä¢ Se pergunta for gen√©rica sobre matr√≠cula/documentos/vagas/hor√°rios SEM especificar:
  ‚Üí Pergunte: "Voc√™ quer saber sobre o curso REGULAR ou T√âCNICO?"

COMO RESPONDER:
‚Ä¢ Se encontrar a informa√ß√£o no contexto: responda completamente
‚Ä¢ Se a informa√ß√£o estiver PARCIAL: forne√ßa o que houver
‚Ä¢ Se realmente N√ÉO houver a informa√ß√£o: "N√£o encontrei essa informa√ß√£o espec√≠fica nos editais."

FORMATA√á√ÉO:
‚Ä¢ Texto direto, sem emojis
‚Ä¢ Use par√°grafos curtos
‚Ä¢ SEMPRE termine com a fonte dos documentos consultados
‚Ä¢ Se usar 1 fonte: "Fonte: Nome do Documento"
‚Ä¢ Se usar 2+ fontes: "Fontes consultadas:" com cada fonte em uma linha iniciada por h√≠fen (-)
"""),

    ("user", """
DOCUMENTOS DISPON√çVEIS:
{contexto}

PERGUNTA DO CANDIDATO:
{input}

Responda com base nos documentos acima. Se a informa√ß√£o estiver presente, forne√ßa-a completamente.
""")
])

# ============================================================
# 5. BUSCA OTIMIZADA
# ============================================================
def extrair_termos_chave(pergunta):
    """Extrai termos importantes da pergunta"""
    stopwords = {
        'o', 'a', 'os', 'as', 'de', 'da', 'do', 'das', 'dos',
        'um', 'uma', 'uns', 'umas', 'para', 'com', 'em', 'no', 
        'na', 'nos', 'nas', 'qual', 'quais', 'quando', 'onde',
        'como', 'que', '√©', 's√£o', 'sobre', 'pelo', 'pela'
    }
    
    palavras = pergunta.lower().split()
    return [p for p in palavras if p not in stopwords and len(p) > 2]

def consultar_agente(base, pergunta, modelo):
    """Busca otimizada com limpeza de texto"""
    
    # Busca sem√¢ntica ampla
    docs_score = base.similarity_search_with_score(pergunta, k=50)
    
    # Busca por termos-chave
    termos = extrair_termos_chave(pergunta)
    if termos:
        query_termos = " ".join(termos)
        docs_termos = base.similarity_search_with_score(query_termos, k=30)
    else:
        docs_termos = []
    
    # Debug
    print(f"\nüîç Buscando: '{pergunta}'", file=sys.stderr)
    print(f"üìä Termos extra√≠dos: {termos}", file=sys.stderr)
    print(f"üìÑ Top 5 resultados:", file=sys.stderr)
    
    for i, (doc, score) in enumerate(docs_score[:5]):
        fonte = Path(doc.metadata.get('source', 'desconhecido')).name
        preview = doc.page_content[:100].replace('\n', ' ')
        print(f"  {i+1}. [{score:.3f}] {fonte[:40]}...", file=sys.stderr)
        print(f"     {preview}...", file=sys.stderr)
    
    # Combinar resultados
    contexto = []
    docs_vistos = set()
    
    # Ordenar por relev√¢ncia (score menor = melhor)
    todos_docs = sorted(docs_score + docs_termos, key=lambda x: x[1])
    
    for doc, score in todos_docs:
        # Threshold MUITO permissivo - baseado nos testes (scores v√£o at√© 7.0+)
        if score > 8.0:
            continue
        
        # Evitar duplicatas
        doc_hash = hash(doc.page_content[:150])
        if doc_hash in docs_vistos:
            continue
        docs_vistos.add(doc_hash)
        
        fonte = Path(doc.metadata.get("source", "")).name
        contexto.append(f"[{fonte}]\n{doc.page_content}\n")
        
        if len(contexto) >= 20:
            break
    
    print(f"‚úì Contexto final: {len(contexto)} documentos selecionados", file=sys.stderr)
    
    if not contexto:
        return "N√£o encontrei informa√ß√µes relevantes sobre essa pergunta nos editais. Poderia reformular ou ser mais espec√≠fico?"
    
    contexto_final = "\n---\n".join(contexto)
    
    # Invocar modelo
    chain = prompt_principal | modelo
    
    resposta = chain.invoke({
        "contexto": contexto_final,
        "input": pergunta
    })
    
    return resposta.content.strip()


# ============================================================
# 6. MAIN
# ============================================================
def main():
    if len(sys.argv) < 2:
        print("Erro: Pergunta n√£o fornecida.")
        sys.exit(1)

    pergunta = sys.argv[1]
    chave = os.getenv("GROQ_API_KEY")

    if not chave:
        print("Erro: GROQ_API_KEY n√£o configurada.")
        sys.exit(1)

    try:
        print("üöÄ Inicializando Agente CPM...", file=sys.stderr)
        
        modelo = ChatGroq(
            api_key=chave,
            model="llama-3.3-70b-versatile",
            temperature=0.1
        )

        print("üìö Carregando editais...", file=sys.stderr)
        base = carregar_pdfs_cpm()

        print(f"üí¨ Consultando...", file=sys.stderr)
        resposta = consultar_agente(base, pergunta, modelo)

        print("\n" + resposta)

    except Exception as e:
        print(f"ERRO: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()